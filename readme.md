# MLOps Fundamentals Capstone - Complete Series Guide

## ðŸ“š Overview

This is the **complete guide** for the MLOps Fundamentals 3-part capstone project series. This document explains how the three projects interconnect, the progression path, and how to use them as an integrated learning system.

---

## ðŸŽ¯ Project Series Summary

### Part 1: Foundations (2 weeks)
**Focus:** Core ML pipeline fundamentals

Build a complete ML model training and serving system with proper versioning and containerization.

**Key Skills:**
- Model training and evaluation
- MLflow experiment tracking
- Model registry management
- FastAPI REST API development
- Docker containerization
- Unit testing for ML code

**Deliverables:**
- Working training script
- MLflow experiment tracking
- FastAPI prediction API
- Docker container
- Test suite (>80% coverage)

**Tech Stack:**
```
Core: scikit-learn, FastAPI, MLflow, Docker
Data: pandas, numpy, NLTK
Testing: pytest
```

---

### Part 2: Monitoring & Automation (2 weeks)
**Focus:** Observability and automated workflows

Build on Part 1 to add drift detection, scheduled retraining, and monitoring dashboards.

**Key Skills:**
- Data drift detection
- Scheduled task automation (APScheduler)
- Performance monitoring
- Dashboard design (Streamlit)
- Model comparison
- Automated decision-making
- SQLite database management

**Deliverables:**
- Drift detection module
- Scheduled retraining system
- Monitoring dashboard
- Model comparison logic
- Retraining history database
- Extended test suite

**Tech Stack:**
```
Scheduling: APScheduler
Dashboards: Streamlit
Drift: Evidently (or custom)
Database: SQLAlchemy, SQLite
```

**Dependency:** âœ… Part 1 must be complete

---

### Part 3: Advanced Intelligence (2-3 weeks)
**Focus:** Intelligent decision-making and enterprise deployment

Build on Parts 1 & 2 to add LangChain agents, alerts, A/B testing, and production orchestration.

**Key Skills:**
- LangChain agent development
- LLM integration (OpenAI, Anthropic)
- Multi-channel alerting systems
- A/B testing frameworks
- API security (authentication, audit logging)
- Docker Compose orchestration
- Performance monitoring and observability
- Production deployment strategies

**Deliverables:**
- LangChain retraining agent
- Email/Slack alert system
- A/B testing framework
- Advanced observability (Prometheus)
- API authentication
- Audit logging system
- Docker Compose full stack
- End-to-end integration tests
- Production deployment guide
- Demo video

**Tech Stack:**
```
AI: LangChain, OpenAI/Anthropic APIs
Alerts: smtplib, slack-sdk
Observability: Prometheus
Security: PyJWT, cryptography
Orchestration: Docker Compose
```

**Dependency:** âœ… Parts 1 & 2 must be complete

---

## ðŸ”„ How the Parts Connect

### Part 1 â†’ Part 2 Transition

```
Part 1 Output                 Part 2 Input
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Trained model        â†’      Use for predictions
âœ“ MLflow registry      â†’      Retrieve models
âœ“ FastAPI API          â†’      Add monitoring endpoints
âœ“ Docker setup         â†’      Extend with new services
âœ“ Training code        â†’      Automate with scheduler
```

**What Part 2 adds:**
```python
# Part 1: Single prediction
{"message": "text"} â†’ model â†’ {"prediction": "spam"}

# Part 2: Monitoring layer
Monitor production predictions
  â†“
Detect drift in incoming data
  â†“
Compare metrics against thresholds
  â†“
Trigger retraining automatically
  â†“
Deploy new model if improved
```

### Part 2 â†’ Part 3 Transition

```
Part 2 Output                 Part 3 Input
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ“ Drift metrics        â†’      Agent analyzes metrics
âœ“ Monitoring service   â†’      Agent subscribes to events
âœ“ Retraining logic     â†’      Agent makes decisions
âœ“ Model versions       â†’      Agent selects best model
âœ“ Dashboard            â†’      Agent provides context
```

**What Part 3 adds:**
```python
# Part 2: Rule-based trigger
if drift > 0.15 or accuracy < 0.93:
    trigger_retraining()

# Part 3: Intelligent agent
Agent observes metrics
  â†“
LLM analyzes patterns and context
  â†“
Agent reasons about spam evolution
  â†“
Agent decides: retrain, wait, or alert
  â†“
Agent sends alerts via email/Slack
  â†“
Agent implements A/B testing
```

---

## ðŸ“Š Scope Distribution

### Part 1: Foundations (35% of total scope)

**Core Requirements Covered:**
- âœ… FR01: Model Training Script
- âœ… FR02: Hyperparameter Tuning
- âœ… FR03: MLflow Integration
- âœ… FR04: Model Registry
- âœ… FR05: Docker Containerization
- âœ… FR06: FastAPI Prediction API
- âœ… FR07: Text Preprocessing
- âœ… FR08: Model Persistence

**Non-Functional Requirements Covered:**
- âœ… NFR01: Training Time (<2 min)
- âœ… NFR02: API Response Time (<100ms)
- âœ… NFR08: Container Startup (<30s)
- âœ… NFR09: Model Accuracy (>95%)

**Concepts Introduced:**
- Model training workflows
- Experiment tracking
- API development
- Containerization

---

### Part 2: Monitoring & Automation (35% of total scope)

**Core Requirements Covered:**
- âœ… FR06: Text Drift Detection
- âœ… FR07: Drift Metrics
- âœ… FR08: Scheduled Retraining
- âœ… FR09: Monitoring Service
- âœ… FR10: Model Comparison
- âœ… FR11: Conditional Deployment
- âœ… FR12: Dashboard Metrics
- âœ… FR13: Alert Triggers
- âœ… FR14: Historical Tracking

**Non-Functional Requirements Covered:**
- âœ… NFR03: Text Preprocessing Time (<50ms)
- âœ… NFR05: Model Registry Access (<2s)
- âœ… NFR06: Retraining Trigger Reliability (>90%)
- âœ… NFR07: Dashboard Load Time (<3s)

**Concepts Introduced:**
- Drift detection
- Scheduled automation
- Observability
- Statistical analysis
- Dashboard design

---

### Part 3: Advanced Intelligence (30% of total scope)

**Core Requirements Covered:**
- âœ… FR07: Retraining Agent (with LLM)
- âœ… FR10: Alert System (multi-channel)
- âœ… Advanced: A/B Testing
- âœ… Advanced: Security
- âœ… Advanced: Full Orchestration
- âœ… Advanced: Integration Testing
- âœ… Advanced: Production Deployment

**Concepts Introduced:**
- Intelligent agents
- LLM integration
- Multi-channel communication
- A/B testing
- Security & authentication
- Orchestration patterns
- Production deployment

---

## ðŸŽ¯ Learning Path

### Week 1-2: Part 1 Fundamentals
```
Day 1-2:  Setup, data exploration, requirements
Day 3-4:  Model training pipeline
Day 5-6:  MLflow integration
Day 7-8:  FastAPI serving
Day 9-10: Docker containerization
Day 11-12: Testing and documentation
Day 13-14: Polish, demo, presentation
```

### Week 3-4: Part 2 Monitoring
```
Day 1-2:  Drift detection theory & implementation
Day 3-4:  APScheduler integration
Day 5-6:  Monitoring service
Day 7-8:  Streamlit dashboard
Day 9-10: Model comparison & deployment logic
Day 11-12: Advanced testing
Day 13-14: Polish, integration testing, presentation
```

### Week 5-6: Part 3 Intelligence
```
Day 1-2:  LangChain & agent architecture
Day 3-4:  LLM integration
Day 5-6:  Alert systems
Day 7-8:  A/B testing framework
Day 9-10: Security & audit logging
Day 11-12: Docker Compose orchestration
Day 13-14: Integration tests, deployment guide, demo
```

---

## ðŸ”— Repository Organization

### Recommended Setup

**Option A: Separate Repositories (Recommended)**
```
GitHub Account
â”œâ”€â”€ MLOps-Fundamentals-Capstone-Part1-Foundations/
â”‚   â””â”€â”€ Complete Part 1 code
â”‚
â”œâ”€â”€ MLOps-Fundamentals-Capstone-Part2-Monitoring/
â”‚   â””â”€â”€ Complete Part 2 code (builds on Part 1)
â”‚
â””â”€â”€ MLOps-Fundamentals-Capstone-Part3-Advanced/
    â””â”€â”€ Complete Part 3 code (builds on Parts 1 & 2)
```

**Option B: Monorepo with Branches**
```
MLOps-Fundamentals-Capstone/
â”œâ”€â”€ main (Part 3 complete)
â”‚
â”œâ”€â”€ part-1-foundations (Part 1 only)
â”œâ”€â”€ part-2-monitoring (Parts 1 & 2)
â””â”€â”€ part-3-advanced (All parts)
```

### Recommended: Option A (Separate Repos)
- âœ… Clear progression
- âœ… Each repo can be submitted independently
- âœ… Better for portfolio showcase
- âœ… Easier to manage dependencies

---

## ðŸ—ï¸ Architecture Progression

### Part 1: Simple Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Training   â”‚
â”‚   Script     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ MLflow  â”‚ (versioning)
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI API    â”‚ (predictions)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Part 2: Extended Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Training   â”‚    â”‚  New Messages    â”‚
â”‚   Script     â”‚    â”‚  (production)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                    â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ MLflow  â”‚      â”‚ Drift Detection â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                    â”‚
        â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚          â”‚ Monitoring Svc    â”‚
        â”‚          â”‚ (scheduled check) â”‚
        â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    FastAPI API (+ monitoring endpoints) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Streamlit     â”‚
       â”‚ Dashboard     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Part 3: Full Enterprise Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Training   â”‚    â”‚  New Messages    â”‚    â”‚  Users/Apps  â”‚
â”‚   Script     â”‚    â”‚  (production)    â”‚    â”‚   (web/API)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                    â”‚                   â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ MLflow  â”‚      â”‚ Drift Detection â”‚    â”‚ Auth/Sec  â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚                    â”‚                   â”‚
        â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
        â”‚          â”‚ Monitoring Svc    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚          â”‚ + LangChain Agent â”‚         â”‚
        â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
        â”‚                   â”‚                    â”‚
        â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
        â”‚          â”‚  Alert System   â”‚           â”‚
        â”‚          â”‚(Email/Slack)    â”‚           â”‚
        â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
        â”‚                   â”‚                    â”‚
        â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
        â”‚          â”‚  A/B Testing    â”‚           â”‚
        â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
        â”‚                   â”‚                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 FastAPI API (Production)                    â”‚
â”‚              (+ auth, observability, audit log)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                                 â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
       â”‚ Streamlit     â”‚             â”‚  Prometheus     â”‚
       â”‚ Dashboard     â”‚             â”‚  Metrics        â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“ Code Reuse Strategy

### Part 1 Code â†’ Part 2
```python
# Part 1: src/train.py
def train_model(data, model_type='logistic_regression'):
    # Training logic
    return model, vectorizer, metrics

# Part 2: Can call directly without modification
from src.train import train_model

# Part 2 adds retraining wrapper
def retrain_if_needed():
    if drift_detected or accuracy_low:
        model, vec, metrics = train_model(new_data)
        compare_and_deploy(model)
```

### Part 2 Code â†’ Part 3
```python
# Part 2: src/monitor.py
class MonitoringService:
    def check_retraining_needed(self):
        return {
            'drift': self.calculate_drift(),
            'accuracy': self.evaluate_model(),
            'recommendation': 'RETRAIN' if drift > threshold else 'OK'
        }

# Part 3: Agent uses this directly
from src.monitor import MonitoringService

class RetrainingAgent:
    def __init__(self):
        self.monitor = MonitoringService()
    
    async def decide(self):
        metrics = self.monitor.check_retraining_needed()
        # Use LLM to reason about metrics
        decision = await self.llm.analyze(metrics)
        # Send alerts, trigger retraining
```

---

## âœ… Success Criteria by Part

### Part 1 Success Criteria
- âœ… Model achieves >95% accuracy on test set
- âœ… Training completes in <2 minutes
- âœ… API responds in <100ms per request
- âœ… Code coverage >80%
- âœ… Docker container builds and runs
- âœ… All unit tests pass
- âœ… Full documentation provided
- âœ… Demo video shows training â†’ serving workflow

### Part 2 Success Criteria
- âœ… All Part 1 criteria maintained
- âœ… Drift detection accuracy >85%
- âœ… Scheduled retraining works reliably (>90% trigger accuracy)
- âœ… Dashboard loads in <3s
- âœ… Model comparison works correctly
- âœ… Retraining history is tracked
- âœ… Integration tests pass (Part 1 + Part 2)
- âœ… Demo shows full monitoring and retraining workflow

### Part 3 Success Criteria
- âœ… All Part 1 & 2 criteria maintained
- âœ… Agent makes decisions with >95% accuracy
- âœ… Alerts send in <60s
- âœ… A/B testing routes traffic correctly
- âœ… API authentication works on all endpoints
- âœ… Audit log is complete and accurate
- âœ… Docker Compose orchestrates all services
- âœ… End-to-end integration tests pass
- âœ… Production deployment guide is complete
- âœ… Demo video shows all features working together

---

## ðŸš€ Deployment Progression

### Part 1: Local Development
```bash
# Local training
python src/train.py

# Local API
uvicorn src.serve:app --reload

# Docker container
docker build -t spam-detector:v1 .
docker run -p 8000:8000 spam-detector:v1
```

### Part 2: Local with Monitoring
```bash
# Multiple local processes
mlflow server
uvicorn src.serve:app
python src/monitor.py
streamlit run src/dashboard.py
```

### Part 3: Full Docker Compose
```bash
# Single command for full stack
docker-compose up --build

# Production-ready orchestration
# Includes: MLflow, FastAPI, Streamlit, Agent, DB, Prometheus
```

---

## ðŸ“š Skills Progression

```
Part 1: Foundations
â”œâ”€â”€ Python fundamentals
â”œâ”€â”€ ML libraries (scikit-learn)
â”œâ”€â”€ API development (FastAPI)
â”œâ”€â”€ ML experiment tracking (MLflow)
â”œâ”€â”€ Docker basics
â””â”€â”€ Testing (pytest)

Part 2: Intermediate
â”œâ”€â”€ Statistical analysis (drift detection)
â”œâ”€â”€ Data engineering (preprocessing at scale)
â”œâ”€â”€ Task scheduling (APScheduler)
â”œâ”€â”€ Dashboard design (Streamlit)
â”œâ”€â”€ Database management (SQLite)
â”œâ”€â”€ Performance analysis
â””â”€â”€ System monitoring

Part 3: Advanced
â”œâ”€â”€ AI agents (LangChain)
â”œâ”€â”€ LLM integration
â”œâ”€â”€ System design (orchestration)
â”œâ”€â”€ Security & authentication
â”œâ”€â”€ Observability (Prometheus)
â”œâ”€â”€ Production operations
â”œâ”€â”€ End-to-end testing
â””â”€â”€ DevOps practices
```

---

## ðŸŽ“ Portfolio Showcase

### How to Present Each Part

**Part 1 Presentation:**
- "I built an end-to-end ML pipeline for spam detection"
- Show: MLflow UI, API docs, Docker image
- Emphasize: Model performance, code quality, testing

**Part 2 Presentation:**
- "I added intelligent monitoring to detect data drift"
- Show: Drift metrics, monitoring dashboard, retraining history
- Emphasize: Automation, observability, decision logic

**Part 3 Presentation:**
- "I completed a production-ready MLOps system with AI agents"
- Show: Agent reasoning, multi-channel alerts, full orchestration
- Emphasize: Enterprise readiness, intelligent automation, security

**Complete Portfolio Achievement:**
- "I designed and built a complete production MLOps system"
- Show: All three projects integrated
- Emphasize: End-to-end workflow, intelligent decisions, enterprise features

---

## ðŸ”— Cross-Project Dependencies

### Environment Variables
```bash
# Part 1
MLFLOW_TRACKING_URI=http://localhost:5000

# Part 2 (extends Part 1)
MLFLOW_TRACKING_URI=http://localhost:5000
DB_PATH=data/retraining_history.db

# Part 3 (extends Parts 1 & 2)
MLFLOW_TRACKING_URI=http://localhost:5000
DB_PATH=data/retraining_history.db
OPENAI_API_KEY=sk-...
SLACK_WEBHOOK_URL=https://hooks.slack.com/...
SMTP_SERVER=smtp.gmail.com
ALERT_EMAIL=your-email@example.com
```

### Shared Database
```
Part 1: No persistent state beyond MLflow
Part 2: SQLite for retraining history
Part 3: Extends SQLite for alerts, A/B test results
```

### Shared Configuration
```python
# src/config.py - shared across all parts
DRIFT_THRESHOLD = 0.15
ACCURACY_THRESHOLD = 0.93
RETRAINING_SCHEDULE = 'weekly'  # Part 2+
AB_TEST_SPLIT = 0.2             # Part 3+
```

---

## ðŸ¤” Common Pitfalls & Solutions

### Pitfall 1: Not Completing Part 1 Before Part 2
**Problem:** Trying to add monitoring without a solid foundation
**Solution:** 
- Complete all Part 1 tests first
- Have Part 1 running in production before starting Part 2
- Use `make test` to verify everything works

### Pitfall 2: Skipping Testing
**Problem:** Code works locally but fails in monitoring
**Solution:**
- Write tests as you go (TDD)
- Aim for >80% coverage in each part
- Test the integration points between parts

### Pitfall 3: Ignoring Documentation
**Problem:** Reviewers can't understand your decisions
**Solution:**
- Document architecture decisions
- Explain monitoring thresholds
- Provide runbooks for failures

### Pitfall 4: Over-Engineering Early
**Problem:** Spending too much time on optimization in Part 1
**Solution:**
- Follow the 80/20 rule
- Get it working first
- Optimize in Part 3 if needed

---

## ðŸ“– Additional Resources

### Part 1 Resources
- [scikit-learn documentation](https://scikit-learn.org/)
- [MLflow quickstart](https://mlflow.org/docs/latest/quickstart.html)
- [FastAPI tutorial](https://fastapi.tiangolo.com/tutorial/)
- [Docker for ML](https://docs.docker.com/)

### Part 2 Resources
- [APScheduler documentation](https://apscheduler.readthedocs.io/)
- [Streamlit documentation](https://docs.streamlit.io/)
- [Drift detection patterns](https://docs.evidentlyai.com/)
- [Time series analysis](https://pandas.pydata.org/docs/)

### Part 3 Resources
- [LangChain documentation](https://docs.langchain.com/)
- [OpenAI API reference](https://platform.openai.com/docs/)
- [Docker Compose guide](https://docs.docker.com/compose/)
- [Prometheus monitoring](https://prometheus.io/docs/)

---

## ðŸŽ¯ What's Next After All 3 Parts?

After completing the full series, you could:

1. **Cloud Deployment**
   - Deploy to AWS/GCP/Azure
   - Use managed services (SageMaker, Vertex AI)
   - Implement auto-scaling

2. **Advanced Features**
   - Feature store integration
   - Model explainability (SHAP, LIME)
   - Adversarial testing
   - Model compression

3. **Specialized Domains**
   - Computer Vision pipelines
   - NLP-specific techniques (transformers)
   - Time series forecasting
   - Reinforcement learning

4. **Production Hardening**
   - Kubernetes deployment
   - Multi-region setup
   - Disaster recovery
   - Compliance (GDPR, HIPAA)

---

## ðŸ“ž Getting Help

For each part:
- **Part 1 Issues:** Check [MLOps-Fundamentals-Capstone-Part1-Foundations README](https://github.com/cafc79/MLOps-fundamentals/tree/Foundations)
- **Part 2 Issues:** Check [MLOps-Fundamentals-Capstone-Part2-Monitoring README](https://github.com/cafc79/MLOps-fundamentals/tree/Monitoring)
- **Part 3 Issues:** Check [MLOps-Fundamentals-Capstone-Part3-Advanced README](https://github.com/cafc79/MLOps-fundamentals/tree/Advanced)

---

## ðŸŽ‰ Conclusion

This 3-part series takes you from ML fundamentals to a production-ready MLOps system. Each part builds logically on the previous one, teaching essential skills at each level.

**Part 1:** Build the foundation
**Part 2:** Add intelligence and automation
**Part 3:** Create an enterprise system

Good luck! ðŸš€
